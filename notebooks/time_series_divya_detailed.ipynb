{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Time Series Experiment Runner\n",
    "\n",
    "\n",
    "\n",
    " This notebook compares multiple forecasting approaches:\n",
    "\n",
    " - **Baselines:** Naive, Moving Average\n",
    "\n",
    " - **ML Models:** Random Forest, XGBoost\n",
    "\n",
    " - **Deep Learning:** LSTM, GRU\n",
    "\n",
    " - **Strategies:** Direct vs Recursive forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 19:44:27.452744: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-28 19:44:27.503993: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-28 19:44:28.321885: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-28 19:44:31.827120: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-28 19:44:31.832829: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "tf.get_logger().setLevel('ERROR')  # Suppress TF warnings\n",
    "\n",
    "# Progress bar (falls back to simple print if not installed)\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    HAS_TQDM = True\n",
    "except ImportError:\n",
    "    HAS_TQDM = False\n",
    "    def tqdm(iterable, desc=\"\", total=None):\n",
    "        for i, item in enumerate(iterable):\n",
    "            print(f\"  {desc} [{i+1}/{total or '?'}]\", end='\\r')\n",
    "            yield item\n",
    "        print()\n",
    "\n",
    "print(\"Imports complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Target: log_price\n",
      "  Horizons: [1, 3, 6, 12]\n",
      "  Sequence lengths: [4, 6, 12]\n",
      "  Train end year: 2019\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "# Modify these to adjust your experiments\n",
    "\n",
    "TARGET = 'log_price'\n",
    "HORIZONS = [1, 3, 6, 12]\n",
    "SEQ_LENGTHS = [4, 6, 12]\n",
    "TRAIN_END_YEAR = 2019\n",
    "\n",
    "# Deep learning settings\n",
    "DL_EPOCHS = 50\n",
    "DL_BATCH_SIZE = 32\n",
    "DL_PATIENCE = 10  # Early stopping patience\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Target: {TARGET}\")\n",
    "print(f\"  Horizons: {HORIZONS}\")\n",
    "print(f\"  Sequence lengths: {SEQ_LENGTHS}\")\n",
    "print(f\"  Train end year: {TRAIN_END_YEAR}\")\n",
    "\n",
    "train_df = pd.read_csv(\"../tsa_train.csv\")\n",
    "test_df = pd.read_csv(\"../tsa_test.csv\")\n",
    "train_df['split'] = 'train'\n",
    "test_df['split'] = 'test'\n",
    "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "full_df = full_df.sort_values(['region', 'period_begin']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# === HELPER FUNCTIONS ===\n",
    "\n",
    "def log(msg):\n",
    "    \"\"\"Print with timestamp.\"\"\"\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {msg}\")\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    \"\"\"Calculate all metrics.\"\"\"\n",
    "    return {\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'mae': mean_absolute_error(y_true, y_pred),\n",
    "        'r2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def create_features_for_horizon(df, target_col, seq_length, horizon):\n",
    "    \"\"\"Create lag/trend features for time series forecasting.\"\"\"\n",
    "    feature_dfs = []\n",
    "    for zip_code in df['region'].unique():\n",
    "        zip_df = df[df['region'] == zip_code].sort_values('period_begin').copy()\n",
    "        if len(zip_df) < seq_length + horizon:\n",
    "            continue\n",
    "        \n",
    "        # Lag features\n",
    "        for lag in range(1, seq_length + 1):\n",
    "            shift_amount = lag + horizon - 1\n",
    "            zip_df[f'lag_{lag}'] = zip_df[target_col].shift(shift_amount)\n",
    "        \n",
    "        # Trend features (log-spaced)\n",
    "        n_trends = min(int(np.ceil(np.log2(seq_length))), 5)\n",
    "        trend_points = np.unique(np.geomspace(2, seq_length, n_trends, dtype=int))\n",
    "        for n in trend_points:\n",
    "            if n <= seq_length:\n",
    "                zip_df[f'trend_{n}'] = zip_df['lag_1'] - zip_df[f'lag_{n}']\n",
    "        \n",
    "        # Derived features\n",
    "        if seq_length >= 3:\n",
    "            zip_df['momentum'] = zip_df['lag_1'] - 2*zip_df['lag_2'] + zip_df['lag_3']\n",
    "        else:\n",
    "            zip_df['momentum'] = zip_df['lag_1'] - zip_df['lag_2']\n",
    "        zip_df['volatility'] = zip_df[target_col].rolling(window=seq_length).std().shift(horizon)\n",
    "        zip_df['rolling_mean'] = zip_df[target_col].rolling(window=seq_length).mean().shift(horizon)\n",
    "        \n",
    "        zip_df['target'] = zip_df[target_col]\n",
    "        feature_dfs.append(zip_df)\n",
    "    \n",
    "    if not feature_dfs:\n",
    "        return None\n",
    "    return pd.concat(feature_dfs, ignore_index=True).dropna().reset_index(drop=True)\n",
    "\n",
    "def get_feature_columns(df):\n",
    "    \"\"\"Return only engineered feature columns.\"\"\"\n",
    "    lag_cols = sorted([c for c in df.columns if c.startswith('lag_')], \n",
    "                      key=lambda x: int(x.split('_')[1]))\n",
    "    trend_cols = sorted([c for c in df.columns if c.startswith('trend_')],\n",
    "                        key=lambda x: int(x.split('_')[1]))\n",
    "    derived_cols = [c for c in ['momentum', 'volatility', 'rolling_mean'] if c in df.columns]\n",
    "    return lag_cols + trend_cols + derived_cols\n",
    "\n",
    "def get_lag_columns(df, seq_length):\n",
    "    \"\"\"Return only lag columns (for LSTM sequence input).\"\"\"\n",
    "    return [f'lag_{i}' for i in range(1, seq_length + 1)]\n",
    "\n",
    "def train_test_split_temporal(df, train_end_year):\n",
    "    \"\"\"Split by year (temporal).\"\"\"\n",
    "    train = df[df['year'] <= train_end_year].copy()\n",
    "    test = df[df['year'] > train_end_year].copy()\n",
    "    return train, test\n",
    "\n",
    "print(\"✅ Helper functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model definitions complete\n",
      "   ML models: ['RF_default', 'RF_tuned', 'XGB_default', 'XGB_tuned']\n",
      "   DL models: ['LSTM_small', 'LSTM_medium', 'LSTM_large', 'GRU_small', 'GRU_medium']\n"
     ]
    }
   ],
   "source": [
    "# === ML MODELS ===\n",
    "\n",
    "def get_ml_models():\n",
    "    \"\"\"Return dict of ML model_name -> model_instance.\"\"\"\n",
    "    return {\n",
    "        'RF_default': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        'RF_tuned': RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1),\n",
    "        'XGB_default': XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
    "        'XGB_tuned': XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42, verbosity=0),\n",
    "    }\n",
    "\n",
    "# === DEEP LEARNING MODELS ===\n",
    "\n",
    "def build_lstm_small(seq_length, n_features=1):\n",
    "    \"\"\"LSTM: 32 units, 1 layer.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(32, input_shape=(seq_length, n_features)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_lstm_medium(seq_length, n_features=1):\n",
    "    \"\"\"LSTM: 64 units, 2 layers.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=(seq_length, n_features)),\n",
    "        LSTM(32),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_lstm_large(seq_length, n_features=1):\n",
    "    \"\"\"LSTM: 128 units, 2 layers + dropout.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(128, return_sequences=True, input_shape=(seq_length, n_features)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_gru_small(seq_length, n_features=1):\n",
    "    \"\"\"GRU: 32 units, 1 layer.\"\"\"\n",
    "    model = Sequential([\n",
    "        GRU(32, input_shape=(seq_length, n_features)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_gru_medium(seq_length, n_features=1):\n",
    "    \"\"\"GRU: 64 units, 2 layers.\"\"\"\n",
    "    model = Sequential([\n",
    "        GRU(64, return_sequences=True, input_shape=(seq_length, n_features)),\n",
    "        GRU(32),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def get_dl_models():\n",
    "    \"\"\"Return dict of DL model builders.\"\"\"\n",
    "    return {\n",
    "        'LSTM_small': build_lstm_small,\n",
    "        'LSTM_medium': build_lstm_medium,\n",
    "        'LSTM_large': build_lstm_large,\n",
    "        'GRU_small': build_gru_small,\n",
    "        'GRU_medium': build_gru_medium,\n",
    "    }\n",
    "\n",
    "print(\"✅ Model definitions complete\")\n",
    "print(f\"   ML models: {list(get_ml_models().keys())}\")\n",
    "print(f\"   DL models: {list(get_dl_models().keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline models defined\n"
     ]
    }
   ],
   "source": [
    "# === BASELINE MODELS ===\n",
    "\n",
    "def naive_forecast(test_df):\n",
    "    \"\"\"Naive: predict lag_1 (most recent known value).\"\"\"\n",
    "    return test_df['lag_1'].values\n",
    "\n",
    "def moving_avg_forecast(test_df, seq_length):\n",
    "    \"\"\"Moving average of all lags.\"\"\"\n",
    "    lag_cols = [f'lag_{i}' for i in range(1, seq_length + 1)]\n",
    "    return test_df[lag_cols].mean(axis=1).values\n",
    "\n",
    "print(\"✅ Baseline models defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Recursive Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Recursive forecasting functions defined\n"
     ]
    }
   ],
   "source": [
    "# === RECURSIVE FORECASTING ===\n",
    "\n",
    "def recursive_forecast_ml(model, test_df, feature_cols, seq_length, target_horizon):\n",
    "    \"\"\"Use horizon=1 ML model to recursively predict multiple steps.\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for idx in range(len(test_df)):\n",
    "        row = test_df.iloc[idx]\n",
    "        sequence = [row[f'lag_{i}'] for i in range(1, seq_length + 1)]\n",
    "        \n",
    "        for step in range(target_horizon):\n",
    "            features = sequence[:seq_length]\n",
    "            \n",
    "            # Add trend features\n",
    "            n_trends = min(int(np.ceil(np.log2(seq_length))), 5)\n",
    "            trend_points = np.unique(np.geomspace(2, seq_length, n_trends, dtype=int))\n",
    "            for n in trend_points:\n",
    "                if n <= seq_length:\n",
    "                    features.append(features[0] - features[n-1])\n",
    "            \n",
    "            # Add derived features\n",
    "            if seq_length >= 3:\n",
    "                features.append(features[0] - 2*features[1] + features[2])\n",
    "            else:\n",
    "                features.append(features[0] - features[1])\n",
    "            features.append(np.std(sequence[:seq_length]))\n",
    "            features.append(np.mean(sequence[:seq_length]))\n",
    "            \n",
    "            pred = model.predict(np.array(features).reshape(1, -1))[0]\n",
    "            sequence = [pred] + sequence[:-1]\n",
    "        \n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "def recursive_forecast_dl(model, test_sequences, seq_length, target_horizon, scaler=None):\n",
    "    \"\"\"Use horizon=1 DL model to recursively predict multiple steps.\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for seq in test_sequences:\n",
    "        current_seq = seq.copy()\n",
    "        \n",
    "        for step in range(target_horizon):\n",
    "            # Reshape for prediction\n",
    "            X = current_seq.reshape(1, seq_length, 1)\n",
    "            pred = model.predict(X, verbose=0)[0, 0]\n",
    "            \n",
    "            # Slide window\n",
    "            current_seq = np.roll(current_seq, -1)\n",
    "            current_seq[-1] = pred\n",
    "        \n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "print(\"✅ Recursive forecasting functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Main Experiment Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Experiment runner ready\n"
     ]
    }
   ],
   "source": [
    "# === EXPERIMENT RUNNER ===\n",
    "\n",
    "def run_all_experiments(full_df, run_baselines=True, run_ml=True, run_dl=True, run_recursive=True):\n",
    "    \"\"\"\n",
    "    Run all experiments.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    full_df : DataFrame with preprocessed data\n",
    "    run_baselines : bool, run Naive/MovingAvg\n",
    "    run_ml : bool, run RF/XGBoost\n",
    "    run_dl : bool, run LSTM/GRU\n",
    "    run_recursive : bool, run recursive forecasting comparison\n",
    "    \"\"\"\n",
    "    global results\n",
    "    results = []\n",
    "    \n",
    "    # Count total experiments\n",
    "    n_configs = len(HORIZONS) * len(SEQ_LENGTHS)\n",
    "    n_baselines = 2 if run_baselines else 0\n",
    "    n_ml = len(get_ml_models()) if run_ml else 0\n",
    "    n_dl = len(get_dl_models()) if run_dl else 0\n",
    "    total = n_configs * (n_baselines + n_ml + n_dl)\n",
    "    \n",
    "    log(f\"Starting {total} experiments\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    exp_count = 0\n",
    "    \n",
    "    # ========================================\n",
    "    # DIRECT FORECASTING\n",
    "    # ========================================\n",
    "    for horizon in HORIZONS:\n",
    "        for seq_length in SEQ_LENGTHS:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            log(f\"HORIZON={horizon}, SEQ_LENGTH={seq_length}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Create features\n",
    "            df_features = create_features_for_horizon(full_df, TARGET, seq_length, horizon)\n",
    "            if df_features is None:\n",
    "                log(\"⚠️  SKIP: Not enough data\")\n",
    "                continue\n",
    "            \n",
    "            # Split data\n",
    "            train_df, test_df = train_test_split_temporal(df_features, TRAIN_END_YEAR)\n",
    "            feature_cols = get_feature_columns(train_df)\n",
    "            lag_cols = get_lag_columns(train_df, seq_length)\n",
    "            \n",
    "            X_train = train_df[feature_cols].values\n",
    "            y_train = train_df['target'].values\n",
    "            X_test = test_df[feature_cols].values\n",
    "            y_test = test_df['target'].values\n",
    "            \n",
    "            # For DL: extract just lag sequences\n",
    "            X_train_seq = train_df[lag_cols].values.reshape(-1, seq_length, 1)\n",
    "            X_test_seq = test_df[lag_cols].values.reshape(-1, seq_length, 1)\n",
    "            \n",
    "            # Scale for DL\n",
    "            scaler = StandardScaler()\n",
    "            X_train_seq_scaled = scaler.fit_transform(X_train_seq.reshape(-1, seq_length)).reshape(-1, seq_length, 1)\n",
    "            X_test_seq_scaled = scaler.transform(X_test_seq.reshape(-1, seq_length)).reshape(-1, seq_length, 1)\n",
    "            \n",
    "            log(f\"Train: {len(train_df):,} | Test: {len(test_df):,} | Features: {len(feature_cols)}\")\n",
    "            \n",
    "            # --- BASELINES ---\n",
    "            if run_baselines:\n",
    "                for name, forecast_fn in [('Naive', naive_forecast), ('MovingAvg', lambda df: moving_avg_forecast(df, seq_length))]:\n",
    "                    exp_count += 1\n",
    "                    y_pred = forecast_fn(test_df)\n",
    "                    metrics = evaluate(y_test, y_pred)\n",
    "                    results.append({\n",
    "                        'strategy': 'direct', 'model': name, 'horizon': horizon,\n",
    "                        'seq_length': seq_length, **metrics, 'n_train': len(train_df), 'n_test': len(test_df)\n",
    "                    })\n",
    "                    print(f\"  ✓ [{exp_count}/{total}] {name:<15} RMSE={metrics['rmse']:.4f}  R²={metrics['r2']:.4f}\")\n",
    "            \n",
    "            # --- ML MODELS ---\n",
    "            if run_ml:\n",
    "                for name, model in get_ml_models().items():\n",
    "                    exp_count += 1\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    metrics = evaluate(y_test, y_pred)\n",
    "                    results.append({\n",
    "                        'strategy': 'direct', 'model': name, 'horizon': horizon,\n",
    "                        'seq_length': seq_length, **metrics, 'n_train': len(train_df), 'n_test': len(test_df)\n",
    "                    })\n",
    "                    print(f\"  ✓ [{exp_count}/{total}] {name:<15} RMSE={metrics['rmse']:.4f}  R²={metrics['r2']:.4f}\")\n",
    "            \n",
    "            # --- DEEP LEARNING ---\n",
    "            if run_dl:\n",
    "                early_stop = EarlyStopping(monitor='val_loss', patience=DL_PATIENCE, restore_best_weights=True, verbose=0)\n",
    "                \n",
    "                for name, build_fn in get_dl_models().items():\n",
    "                    exp_count += 1\n",
    "                    print(f\"  ⏳ [{exp_count}/{total}] {name:<15} training...\", end='\\r')\n",
    "                    \n",
    "                    model = build_fn(seq_length, n_features=1)\n",
    "                    model.fit(\n",
    "                        X_train_seq_scaled, y_train,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=DL_EPOCHS,\n",
    "                        batch_size=DL_BATCH_SIZE,\n",
    "                        callbacks=[early_stop],\n",
    "                        verbose=0\n",
    "                    )\n",
    "                    y_pred = model.predict(X_test_seq_scaled, verbose=0).flatten()\n",
    "                    metrics = evaluate(y_test, y_pred)\n",
    "                    results.append({\n",
    "                        'strategy': 'direct', 'model': name, 'horizon': horizon,\n",
    "                        'seq_length': seq_length, **metrics, 'n_train': len(train_df), 'n_test': len(test_df)\n",
    "                    })\n",
    "                    print(f\"  ✓ [{exp_count}/{total}] {name:<15} RMSE={metrics['rmse']:.4f}  R²={metrics['r2']:.4f}\")\n",
    "                    \n",
    "                    # Clear memory\n",
    "                    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # ========================================\n",
    "    # RECURSIVE FORECASTING\n",
    "    # ========================================\n",
    "    if run_recursive:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        log(\"RECURSIVE FORECASTING\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Find best horizon=1 ML model\n",
    "        h1_ml = [r for r in results if r['horizon'] == 1 and r['model'] in get_ml_models().keys()]\n",
    "        h1_dl = [r for r in results if r['horizon'] == 1 and r['model'] in get_dl_models().keys()]\n",
    "        \n",
    "        if h1_ml:\n",
    "            best_ml = min(h1_ml, key=lambda x: x['rmse'])\n",
    "            log(f\"Best ML (h=1): {best_ml['model']} (RMSE={best_ml['rmse']:.4f})\")\n",
    "        if h1_dl:\n",
    "            best_dl = min(h1_dl, key=lambda x: x['rmse'])\n",
    "            log(f\"Best DL (h=1): {best_dl['model']} (RMSE={best_dl['rmse']:.4f})\")\n",
    "        \n",
    "        for seq_length in SEQ_LENGTHS:\n",
    "            # Prepare horizon=1 data\n",
    "            df_h1 = create_features_for_horizon(full_df, TARGET, seq_length, horizon=1)\n",
    "            if df_h1 is None:\n",
    "                continue\n",
    "            \n",
    "            train_df, test_df = train_test_split_temporal(df_h1, TRAIN_END_YEAR)\n",
    "            feature_cols = get_feature_columns(train_df)\n",
    "            lag_cols = get_lag_columns(train_df, seq_length)\n",
    "            \n",
    "            X_train = train_df[feature_cols].values\n",
    "            y_train = train_df['target'].values\n",
    "            \n",
    "            # Train best ML model\n",
    "            if h1_ml:\n",
    "                best_ml_model = get_ml_models()[best_ml['model']]\n",
    "                best_ml_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Train best DL model\n",
    "            if h1_dl:\n",
    "                X_train_seq = train_df[lag_cols].values.reshape(-1, seq_length, 1)\n",
    "                scaler = StandardScaler()\n",
    "                X_train_seq_scaled = scaler.fit_transform(X_train_seq.reshape(-1, seq_length)).reshape(-1, seq_length, 1)\n",
    "                \n",
    "                best_dl_model = get_dl_models()[best_dl['model']](seq_length, n_features=1)\n",
    "                early_stop = EarlyStopping(monitor='val_loss', patience=DL_PATIENCE, restore_best_weights=True, verbose=0)\n",
    "                best_dl_model.fit(X_train_seq_scaled, y_train, validation_split=0.2, \n",
    "                                  epochs=DL_EPOCHS, batch_size=DL_BATCH_SIZE, callbacks=[early_stop], verbose=0)\n",
    "            \n",
    "            # Test at each target horizon\n",
    "            for target_horizon in [3, 6, 12]:\n",
    "                df_direct = create_features_for_horizon(full_df, TARGET, seq_length, target_horizon)\n",
    "                if df_direct is None:\n",
    "                    continue\n",
    "                \n",
    "                _, test_direct = train_test_split_temporal(df_direct, TRAIN_END_YEAR)\n",
    "                y_test = test_direct['target'].values\n",
    "                n_test = min(len(test_df), len(test_direct))\n",
    "                \n",
    "                log(f\"seq={seq_length}, target_horizon={target_horizon}\")\n",
    "                \n",
    "                # Recursive ML\n",
    "                if h1_ml:\n",
    "                    y_pred = recursive_forecast_ml(best_ml_model, test_df.head(n_test), feature_cols, seq_length, target_horizon)\n",
    "                    metrics = evaluate(y_test[:len(y_pred)], y_pred)\n",
    "                    results.append({\n",
    "                        'strategy': 'recursive', 'model': f\"{best_ml['model']}_recursive\", \n",
    "                        'horizon': target_horizon, 'seq_length': seq_length, \n",
    "                        **metrics, 'n_train': len(train_df), 'n_test': len(y_pred)\n",
    "                    })\n",
    "                    print(f\"  ✓ {best_ml['model']}_recursive: RMSE={metrics['rmse']:.4f}  R²={metrics['r2']:.4f}\")\n",
    "                \n",
    "                # Recursive DL\n",
    "                if h1_dl:\n",
    "                    test_seq = test_df.head(n_test)[lag_cols].values\n",
    "                    test_seq_scaled = scaler.transform(test_seq)\n",
    "                    y_pred = recursive_forecast_dl(best_dl_model, test_seq_scaled, seq_length, target_horizon)\n",
    "                    metrics = evaluate(y_test[:len(y_pred)], y_pred)\n",
    "                    results.append({\n",
    "                        'strategy': 'recursive', 'model': f\"{best_dl['model']}_recursive\",\n",
    "                        'horizon': target_horizon, 'seq_length': seq_length,\n",
    "                        **metrics, 'n_train': len(train_df), 'n_test': len(y_pred)\n",
    "                    })\n",
    "                    print(f\"  ✓ {best_dl['model']}_recursive: RMSE={metrics['rmse']:.4f}  R²={metrics['r2']:.4f}\")\n",
    "                \n",
    "                tf.keras.backend.clear_session()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    log(f\"✅ COMPLETE! {len(results)} experiments recorded.\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"✅ Experiment runner ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7. Run Experiments\n",
    "\n",
    "\n",
    "\n",
    " Adjust flags to run subsets:\n",
    "\n",
    " - `run_baselines=True` - Naive, Moving Average\n",
    "\n",
    " - `run_ml=True` - Random Forest, XGBoost\n",
    "\n",
    " - `run_dl=True` - LSTM, GRU (slower)\n",
    "\n",
    " - `run_recursive=True` - Compare direct vs recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:44:33] Starting 132 experiments\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "[19:44:33] HORIZON=1, SEQ_LENGTH=4\n",
      "============================================================\n",
      "[19:44:33] Train: 8,638 | Test: 2,443 | Features: 9\n",
      "  ✓ [1/132] Naive           RMSE=0.1694  R²=0.8330\n",
      "  ✓ [2/132] MovingAvg       RMSE=0.1856  R²=0.7995\n",
      "  ✓ [3/132] RF_default      RMSE=0.1734  R²=0.8250\n",
      "  ✓ [4/132] RF_tuned        RMSE=0.1711  R²=0.8295\n",
      "  ✓ [5/132] XGB_default     RMSE=0.1877  R²=0.7949\n",
      "  ✓ [6/132] XGB_tuned       RMSE=0.1788  R²=0.8140\n",
      "  ⏳ [7/132] LSTM_small      training...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 19:44:38.955088: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ [7/132] LSTM_small      RMSE=0.1683  R²=0.8352\n",
      "  ✓ [8/132] LSTM_medium     RMSE=0.7293  R²=-2.0963\n",
      "  ✓ [9/132] LSTM_large      RMSE=0.3035  R²=0.4639\n",
      "  ✓ [10/132] GRU_small       RMSE=0.6052  R²=-1.1323\n",
      "  ✓ [11/132] GRU_medium      RMSE=1.1807  R²=-7.1150\n",
      "\n",
      "============================================================\n",
      "[19:46:12] HORIZON=1, SEQ_LENGTH=6\n",
      "============================================================\n",
      "[19:46:12] Train: 8,412 | Test: 2,443 | Features: 12\n",
      "  ✓ [12/132] Naive           RMSE=0.1694  R²=0.8330\n",
      "  ✓ [13/132] MovingAvg       RMSE=0.1925  R²=0.7844\n",
      "  ✓ [14/132] RF_default      RMSE=0.1738  R²=0.8242\n",
      "  ✓ [15/132] RF_tuned        RMSE=0.1726  R²=0.8265\n",
      "  ✓ [16/132] XGB_default     RMSE=0.1860  R²=0.7987\n",
      "  ✓ [17/132] XGB_tuned       RMSE=0.1775  R²=0.8167\n",
      "  ✓ [18/132] LSTM_small      RMSE=0.1655  R²=0.8406\n",
      "  ✓ [19/132] LSTM_medium     RMSE=0.7229  R²=-2.0415\n",
      "  ✓ [20/132] LSTM_large      RMSE=0.3231  R²=0.3922\n",
      "  ✓ [21/132] GRU_small       RMSE=0.7397  R²=-2.1846\n",
      "  ✓ [22/132] GRU_medium      RMSE=0.6391  R²=-1.3776\n",
      "\n",
      "============================================================\n",
      "[19:48:12] HORIZON=1, SEQ_LENGTH=12\n",
      "============================================================\n",
      "[19:48:13] Train: 7,734 | Test: 2,443 | Features: 19\n",
      "  ✓ [23/132] Naive           RMSE=0.1694  R²=0.8330\n",
      "  ✓ [24/132] MovingAvg       RMSE=0.2042  R²=0.7573\n",
      "  ✓ [25/132] RF_default      RMSE=0.1635  R²=0.8444\n",
      "  ✓ [26/132] RF_tuned        RMSE=0.1627  R²=0.8459\n",
      "  ✓ [27/132] XGB_default     RMSE=0.1687  R²=0.8344\n",
      "  ✓ [28/132] XGB_tuned       RMSE=0.1626  R²=0.8460\n",
      "  ✓ [29/132] LSTM_small      RMSE=0.1663  R²=0.8390\n",
      "  ✓ [30/132] LSTM_medium     RMSE=0.8203  R²=-2.9166\n",
      "  ✓ [31/132] LSTM_large      RMSE=0.6114  R²=-1.1757\n",
      "  ✓ [32/132] GRU_small       RMSE=0.5780  R²=-0.9448\n",
      "  ✓ [33/132] GRU_medium      RMSE=1.1210  R²=-6.3149\n",
      "\n",
      "============================================================\n",
      "[19:53:44] HORIZON=3, SEQ_LENGTH=4\n",
      "============================================================\n",
      "[19:53:45] Train: 8,412 | Test: 2,443 | Features: 9\n",
      "  ✓ [34/132] Naive           RMSE=0.2459  R²=0.6480\n",
      "  ✓ [35/132] MovingAvg       RMSE=0.2275  R²=0.6988\n",
      "  ✓ [36/132] RF_default      RMSE=0.2412  R²=0.6612\n",
      "  ✓ [37/132] RF_tuned        RMSE=0.2357  R²=0.6766\n",
      "  ✓ [38/132] XGB_default     RMSE=0.2527  R²=0.6282\n",
      "  ✓ [39/132] XGB_tuned       RMSE=0.2366  R²=0.6740\n",
      "  ✓ [40/132] LSTM_small      RMSE=0.2246  R²=0.7063\n",
      "  ✓ [41/132] LSTM_medium     RMSE=0.6164  R²=-1.2118\n",
      "  ✓ [42/132] LSTM_large      RMSE=0.3097  R²=0.4416\n",
      "  ✓ [43/132] GRU_small       RMSE=0.6402  R²=-1.3857\n",
      "  ✓ [44/132] GRU_medium      RMSE=0.7824  R²=-2.5634\n",
      "\n",
      "============================================================\n",
      "[19:55:28] HORIZON=3, SEQ_LENGTH=6\n",
      "============================================================\n",
      "[19:55:28] Train: 8,186 | Test: 2,443 | Features: 12\n",
      "  ✓ [45/132] Naive           RMSE=0.2459  R²=0.6480\n",
      "  ✓ [46/132] MovingAvg       RMSE=0.2232  R²=0.7100\n",
      "  ✓ [47/132] RF_default      RMSE=0.2349  R²=0.6787\n",
      "  ✓ [48/132] RF_tuned        RMSE=0.2324  R²=0.6856\n",
      "  ✓ [49/132] XGB_default     RMSE=0.2444  R²=0.6523\n",
      "  ✓ [50/132] XGB_tuned       RMSE=0.2322  R²=0.6862\n",
      "  ✓ [51/132] LSTM_small      RMSE=0.2118  R²=0.7388\n",
      "  ✓ [52/132] LSTM_medium     RMSE=0.8139  R²=-2.8561\n",
      "  ✓ [53/132] LSTM_large      RMSE=0.5346  R²=-0.6639\n",
      "  ✓ [54/132] GRU_small       RMSE=0.6392  R²=-1.3781\n",
      "  ✓ [55/132] GRU_medium      RMSE=0.7673  R²=-2.4270\n",
      "\n",
      "============================================================\n",
      "[19:57:31] HORIZON=3, SEQ_LENGTH=12\n",
      "============================================================\n",
      "[19:57:31] Train: 7,508 | Test: 2,443 | Features: 19\n",
      "  ✓ [56/132] Naive           RMSE=0.2459  R²=0.6480\n",
      "  ✓ [57/132] MovingAvg       RMSE=0.2258  R²=0.7032\n",
      "  ✓ [58/132] RF_default      RMSE=0.2168  R²=0.7263\n",
      "  ✓ [59/132] RF_tuned        RMSE=0.2146  R²=0.7320\n",
      "  ✓ [60/132] XGB_default     RMSE=0.2272  R²=0.6995\n",
      "  ✓ [61/132] XGB_tuned       RMSE=0.2154  R²=0.7299\n",
      "  ✓ [62/132] LSTM_small      RMSE=0.2098  R²=0.7439\n",
      "  ✓ [63/132] LSTM_medium     RMSE=1.1687  R²=-6.9499\n",
      "  ✓ [64/132] LSTM_large      RMSE=0.4270  R²=-0.0611\n",
      "  ✓ [65/132] GRU_small       RMSE=0.9954  R²=-4.7677\n",
      "  ✓ [66/132] GRU_medium      RMSE=1.1352  R²=-6.5019\n",
      "\n",
      "============================================================\n",
      "[20:12:14] HORIZON=6, SEQ_LENGTH=4\n",
      "============================================================\n",
      "[20:12:15] Train: 8,073 | Test: 2,443 | Features: 9\n",
      "  ✓ [67/132] Naive           RMSE=0.2735  R²=0.5645\n",
      "  ✓ [68/132] MovingAvg       RMSE=0.2455  R²=0.6493\n",
      "  ✓ [69/132] RF_default      RMSE=0.2502  R²=0.6357\n",
      "  ✓ [70/132] RF_tuned        RMSE=0.2441  R²=0.6533\n",
      "  ✓ [71/132] XGB_default     RMSE=0.2579  R²=0.6130\n",
      "  ✓ [72/132] XGB_tuned       RMSE=0.2497  R²=0.6371\n",
      "  ✓ [73/132] LSTM_small      RMSE=0.2374  R²=0.6720\n",
      "  ✓ [74/132] LSTM_medium     RMSE=0.9696  R²=-4.4722\n",
      "  ✓ [75/132] LSTM_large      RMSE=0.3321  R²=0.3580\n",
      "  ✓ [76/132] GRU_small       RMSE=0.6244  R²=-1.2692\n",
      "  ✓ [77/132] GRU_medium      RMSE=1.3517  R²=-9.6357\n",
      "\n",
      "============================================================\n",
      "[20:13:57] HORIZON=6, SEQ_LENGTH=6\n",
      "============================================================\n",
      "[20:13:58] Train: 7,847 | Test: 2,443 | Features: 12\n",
      "  ✓ [78/132] Naive           RMSE=0.2735  R²=0.5645\n",
      "  ✓ [79/132] MovingAvg       RMSE=0.2407  R²=0.6627\n",
      "  ✓ [80/132] RF_default      RMSE=0.2349  R²=0.6787\n",
      "  ✓ [81/132] RF_tuned        RMSE=0.2305  R²=0.6909\n",
      "  ✓ [82/132] XGB_default     RMSE=0.2458  R²=0.6482\n",
      "  ✓ [83/132] XGB_tuned       RMSE=0.2323  R²=0.6858\n",
      "  ✓ [84/132] LSTM_small      RMSE=0.2296  R²=0.6931\n",
      "  ✓ [85/132] LSTM_medium     RMSE=0.7494  R²=-2.2687\n",
      "  ✓ [86/132] LSTM_large      RMSE=0.3312  R²=0.3613\n",
      "  ✓ [87/132] GRU_small       RMSE=0.6148  R²=-1.2005\n",
      "  ✓ [88/132] GRU_medium      RMSE=1.0488  R²=-5.4024\n",
      "\n",
      "============================================================\n",
      "[20:15:48] HORIZON=6, SEQ_LENGTH=12\n",
      "============================================================\n",
      "[20:15:49] Train: 7,169 | Test: 2,443 | Features: 19\n",
      "  ✓ [89/132] Naive           RMSE=0.2735  R²=0.5645\n",
      "  ✓ [90/132] MovingAvg       RMSE=0.2458  R²=0.6482\n",
      "  ✓ [91/132] RF_default      RMSE=0.2227  R²=0.7114\n",
      "  ✓ [92/132] RF_tuned        RMSE=0.2198  R²=0.7188\n",
      "  ✓ [93/132] XGB_default     RMSE=0.2435  R²=0.6549\n",
      "  ✓ [94/132] XGB_tuned       RMSE=0.2297  R²=0.6929\n",
      "  ✓ [95/132] LSTM_small      RMSE=0.2175  R²=0.7248\n",
      "  ✓ [96/132] LSTM_medium     RMSE=0.2453  R²=0.6496\n",
      "  ✓ [97/132] LSTM_large      RMSE=0.3736  R²=0.1877\n",
      "  ✓ [98/132] GRU_small       RMSE=1.4082  R²=-10.5432\n",
      "  ✓ [99/132] GRU_medium      RMSE=1.5812  R²=-13.5537\n",
      "\n",
      "============================================================\n",
      "[20:18:32] HORIZON=12, SEQ_LENGTH=4\n",
      "============================================================\n",
      "[20:18:33] Train: 7,395 | Test: 2,443 | Features: 9\n",
      "  ✓ [100/132] Naive           RMSE=0.3039  R²=0.4623\n",
      "  ✓ [101/132] MovingAvg       RMSE=0.2850  R²=0.5270\n",
      "  ✓ [102/132] RF_default      RMSE=0.2617  R²=0.6015\n",
      "  ✓ [103/132] RF_tuned        RMSE=0.2563  R²=0.6176\n",
      "  ✓ [104/132] XGB_default     RMSE=0.2722  R²=0.5686\n",
      "  ✓ [105/132] XGB_tuned       RMSE=0.2586  R²=0.6108\n",
      "  ✓ [106/132] LSTM_small      RMSE=0.2656  R²=0.5895\n",
      "  ✓ [107/132] LSTM_medium     RMSE=1.0254  R²=-5.1208\n",
      "  ✓ [108/132] LSTM_large      RMSE=0.3044  R²=0.4606\n",
      "  ✓ [109/132] GRU_small       RMSE=0.7554  R²=-2.3212\n",
      "  ✓ [110/132] GRU_medium      RMSE=1.2968  R²=-8.7884\n",
      "\n",
      "============================================================\n",
      "[20:20:08] HORIZON=12, SEQ_LENGTH=6\n",
      "============================================================\n",
      "[20:20:09] Train: 7,169 | Test: 2,443 | Features: 12\n",
      "  ✓ [111/132] Naive           RMSE=0.3039  R²=0.4623\n",
      "  ✓ [112/132] MovingAvg       RMSE=0.2814  R²=0.5392\n",
      "  ✓ [113/132] RF_default      RMSE=0.2472  R²=0.6443\n",
      "  ✓ [114/132] RF_tuned        RMSE=0.2419  R²=0.6594\n",
      "  ✓ [115/132] XGB_default     RMSE=0.2565  R²=0.6170\n",
      "  ✓ [116/132] XGB_tuned       RMSE=0.2453  R²=0.6498\n",
      "  ✓ [117/132] LSTM_small      RMSE=0.2528  R²=0.6281\n",
      "  ✓ [118/132] LSTM_medium     RMSE=1.1515  R²=-6.7186\n",
      "  ✓ [119/132] LSTM_large      RMSE=0.3009  R²=0.4729\n",
      "  ✓ [120/132] GRU_small       RMSE=0.6686  R²=-1.6021\n",
      "  ✓ [121/132] GRU_medium      RMSE=1.0781  R²=-5.7661\n",
      "\n",
      "============================================================\n",
      "[20:21:56] HORIZON=12, SEQ_LENGTH=12\n",
      "============================================================\n",
      "[20:21:57] Train: 6,491 | Test: 2,443 | Features: 19\n",
      "  ✓ [122/132] Naive           RMSE=0.3039  R²=0.4623\n",
      "  ✓ [123/132] MovingAvg       RMSE=0.2849  R²=0.5277\n",
      "  ✓ [124/132] RF_default      RMSE=0.2345  R²=0.6800\n",
      "  ✓ [125/132] RF_tuned        RMSE=0.2327  R²=0.6848\n",
      "  ✓ [126/132] XGB_default     RMSE=0.2424  R²=0.6581\n",
      "  ✓ [127/132] XGB_tuned       RMSE=0.2353  R²=0.6776\n",
      "  ✓ [128/132] LSTM_small      RMSE=0.2266  R²=0.7012\n",
      "  ✓ [129/132] LSTM_medium     RMSE=1.3291  R²=-9.2825\n",
      "  ✓ [130/132] LSTM_large      RMSE=0.5278  R²=-0.6217\n",
      "  ✓ [131/132] GRU_small       RMSE=0.9007  R²=-3.7223\n",
      "  ✓ [132/132] GRU_medium      RMSE=1.3209  R²=-9.1555\n",
      "\n",
      "============================================================\n",
      "[20:24:32] RECURSIVE FORECASTING\n",
      "============================================================\n",
      "[20:24:32] Best ML (h=1): XGB_tuned (RMSE=0.1626)\n",
      "[20:24:32] Best DL (h=1): LSTM_small (RMSE=0.1655)\n",
      "[20:25:20] seq=4, target_horizon=3\n",
      "  ✓ XGB_tuned_recursive: RMSE=0.2067  R²=0.7513\n",
      "  ✓ LSTM_small_recursive: RMSE=4.0650  R²=-95.1846\n",
      "[20:35:32] seq=4, target_horizon=6\n",
      "  ✓ XGB_tuned_recursive: RMSE=0.1986  R²=0.7704\n",
      "  ✓ LSTM_small_recursive: RMSE=0.9576  R²=-4.3381\n",
      "[20:57:48] seq=4, target_horizon=12\n",
      "  ✓ XGB_tuned_recursive: RMSE=0.2086  R²=0.7468\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# === RUN EXPERIMENTS ===\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load your data (uncomment and modify path)\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Run all experiments (this will take a while with DL models)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results_df = \u001b[43mrun_all_experiments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfull_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_baselines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_ml\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_dl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Set False for quick test\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_recursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set False for quick test\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 194\u001b[39m, in \u001b[36mrun_all_experiments\u001b[39m\u001b[34m(full_df, run_baselines, run_ml, run_dl, run_recursive)\u001b[39m\n\u001b[32m    192\u001b[39m test_seq = test_df.head(n_test)[lag_cols].values\n\u001b[32m    193\u001b[39m test_seq_scaled = scaler.transform(test_seq)\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m y_pred = \u001b[43mrecursive_forecast_dl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_dl_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_seq_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_horizon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m metrics = evaluate(y_test[:\u001b[38;5;28mlen\u001b[39m(y_pred)], y_pred)\n\u001b[32m    196\u001b[39m results.append({\n\u001b[32m    197\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstrategy\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mrecursive\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_dl[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_recursive\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    198\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhorizon\u001b[39m\u001b[33m'\u001b[39m: target_horizon, \u001b[33m'\u001b[39m\u001b[33mseq_length\u001b[39m\u001b[33m'\u001b[39m: seq_length,\n\u001b[32m    199\u001b[39m     **metrics, \u001b[33m'\u001b[39m\u001b[33mn_train\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(train_df), \u001b[33m'\u001b[39m\u001b[33mn_test\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(y_pred)\n\u001b[32m    200\u001b[39m })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mrecursive_forecast_dl\u001b[39m\u001b[34m(model, test_sequences, seq_length, target_horizon, scaler)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(target_horizon):\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Reshape for prediction\u001b[39;00m\n\u001b[32m     45\u001b[39m     X = current_seq.reshape(\u001b[32m1\u001b[39m, seq_length, \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Slide window\u001b[39;00m\n\u001b[32m     49\u001b[39m     current_seq = np.roll(current_seq, -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:527\u001b[39m, in \u001b[36mTensorFlowTrainer.predict\u001b[39m\u001b[34m(self, x, batch_size, verbose, steps, callbacks)\u001b[39m\n\u001b[32m    522\u001b[39m \u001b[38;5;129m@traceback_utils\u001b[39m.filter_traceback\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    524\u001b[39m     \u001b[38;5;28mself\u001b[39m, x, batch_size=\u001b[38;5;28;01mNone\u001b[39;00m, verbose=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, steps=\u001b[38;5;28;01mNone\u001b[39;00m, callbacks=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    525\u001b[39m ):\n\u001b[32m    526\u001b[39m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m     epoch_iterator = \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module.CallbackList):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:750\u001b[39m, in \u001b[36mTFEpochIterator.__init__\u001b[39m\u001b[34m(self, distribute_strategy, *args, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(*args, **kwargs)\n\u001b[32m    749\u001b[39m \u001b[38;5;28mself\u001b[39m._distribute_strategy = distribute_strategy\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_adapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf.distribute.DistributedDataset):\n\u001b[32m    752\u001b[39m     dataset = \u001b[38;5;28mself\u001b[39m._distribute_strategy.experimental_distribute_dataset(\n\u001b[32m    753\u001b[39m         dataset\n\u001b[32m    754\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:233\u001b[39m, in \u001b[36mArrayDataAdapter.get_tf_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    230\u001b[39m     dataset = dataset.with_options(options)\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m indices_dataset = \u001b[43mindices_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle == \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    235\u001b[39m     indices_dataset = indices_dataset.map(tf.random.shuffle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/dataset_ops.py:2389\u001b[39m, in \u001b[36mDatasetV2.flat_map\u001b[39m\u001b[34m(self, map_func, name)\u001b[39m\n\u001b[32m   2385\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[32m   2386\u001b[39m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[32m   2387\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m   2388\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flat_map_op\n\u001b[32m-> \u001b[39m\u001b[32m2389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflat_map_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_flat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/flat_map_op.py:24\u001b[39m, in \u001b[36m_flat_map\u001b[39m\u001b[34m(input_dataset, map_func, name)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_flat_map\u001b[39m(input_dataset, map_func, name=\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/flat_map_op.py:33\u001b[39m, in \u001b[36m_FlatMapDataset.__init__\u001b[39m\u001b[34m(self, input_dataset, map_func, name)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dataset, map_func, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     32\u001b[39m   \u001b[38;5;28mself\u001b[39m._input_dataset = input_dataset\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m   \u001b[38;5;28mself\u001b[39m._map_func = \u001b[43mstructured_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._map_func.output_structure, dataset_ops.DatasetSpec):\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m     37\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_ops.get_type(\u001b[38;5;28mself\u001b[39m._map_func.output_structure)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[39m, in \u001b[36mStructuredFunctionWrapper.__init__\u001b[39m\u001b[34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[39m\n\u001b[32m    258\u001b[39m       warnings.warn(\n\u001b[32m    259\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    261\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    262\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    263\u001b[39m     fn_factory = trace_tf_function(defun_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[38;5;28mself\u001b[39m._function = \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[32m    267\u001b[39m add_to_graph &= \u001b[38;5;129;01mnot\u001b[39;00m context.executing_eagerly()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1256\u001b[39m, in \u001b[36mFunction.get_concrete_function\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1255\u001b[39m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m   concrete = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m   concrete._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m   1258\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1226\u001b[39m, in \u001b[36mFunction._get_concrete_function_garbage_collected\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1224\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     initializers = []\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28mself\u001b[39m._initialize_uninitialized_variables(initializers)\n\u001b[32m   1229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m   1230\u001b[39m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[32m   1231\u001b[39m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/framework/func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[39m, in \u001b[36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_fn\u001b[39m(*args):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m   ret = \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m   ret = structure.to_tensor_list(\u001b[38;5;28mself\u001b[39m._output_structure, ret)\n\u001b[32m    233\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops.convert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[39m, in \u001b[36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[32m    160\u001b[39m   nested_args = (nested_args,)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m ret = \u001b[43mautograph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m ret = variable_utils.convert_variables_to_tensors(ret)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[39m, in \u001b[36mconvert.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    689\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    692\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m'\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    374\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options.user_requested \u001b[38;5;129;01mand\u001b[39;00m conversion.is_allowlisted(f):\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[32m    381\u001b[39m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options.internal_convert_user_code:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:174\u001b[39m, in \u001b[36mArrayDataAdapter.get_tf_dataset.<locals>.slice_batch_indices\u001b[39m\u001b[34m(indices)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._partial_batch_size:\n\u001b[32m    169\u001b[39m     index_remainder = tf.data.Dataset.from_tensors(\n\u001b[32m    170\u001b[39m         tf.slice(\n\u001b[32m    171\u001b[39m             indices, [num_in_full_batch], [\u001b[38;5;28mself\u001b[39m._partial_batch_size]\n\u001b[32m    172\u001b[39m         )\n\u001b[32m    173\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     flat_dataset = \u001b[43mflat_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_remainder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/dataset_ops.py:1123\u001b[39m, in \u001b[36mDatasetV2.concatenate\u001b[39m\u001b[34m(self, dataset, name)\u001b[39m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# concatenate_op -> dataset_ops).\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m concatenate_op\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/concatenate_op.py:23\u001b[39m, in \u001b[36m_concatenate\u001b[39m\u001b[34m(input_dataset, dataset_to_concatenate, name)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_concatenate\u001b[39m(input_dataset, dataset_to_concatenate, name):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConcatenateDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_to_concatenate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/data/ops/concatenate_op.py:52\u001b[39m, in \u001b[36m_ConcatenateDataset.__init__\u001b[39m\u001b[34m(self, input_dataset, dataset_to_concatenate, name)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mself\u001b[39m._name = name\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m variant_tensor = \u001b[43mgen_dataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_to_concatenate\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_common_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(variant_tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/ops/gen_dataset_ops.py:1104\u001b[39m, in \u001b[36mconcatenate_dataset\u001b[39m\u001b[34m(input_dataset, another_dataset, output_types, output_shapes, metadata, name)\u001b[39m\n\u001b[32m   1102\u001b[39m   metadata = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m metadata = _execute.make_str(metadata, \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m _, _, _op, _outputs = \u001b[43m_op_def_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mConcatenateDataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m                            \u001b[49m\u001b[43manother_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43manother_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m                            \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m                            \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1110\u001b[39m _result = _outputs[:]\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _execute.must_record_gradient():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/framework/op_def_library.py:783\u001b[39m, in \u001b[36m_apply_op_helper\u001b[39m\u001b[34m(op_type_name, name, **keywords)\u001b[39m\n\u001b[32m    778\u001b[39m _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[32m    779\u001b[39m                        keywords, default_type_attr_map, attrs, inputs,\n\u001b[32m    780\u001b[39m                        input_types)\n\u001b[32m    781\u001b[39m _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[32m    782\u001b[39m                        default_type_attr_map, attrs)\n\u001b[32m--> \u001b[39m\u001b[32m783\u001b[39m \u001b[43m_ExtractAttrProto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_protos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m attrs  \u001b[38;5;66;03m# attrs is no longer authoritative, use attr_protos instead\u001b[39;00m\n\u001b[32m    785\u001b[39m _ExtractOutputStructure(op_type_name, op_def, attr_protos,\n\u001b[32m    786\u001b[39m                         output_structure)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/framework/op_def_library.py:329\u001b[39m, in \u001b[36m_ExtractAttrProto\u001b[39m\u001b[34m(op_type_name, op_def, attrs, attr_protos)\u001b[39m\n\u001b[32m    326\u001b[39m   attr_protos[key] = attr_value\n\u001b[32m    327\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m attr_value = \u001b[43mvalue_to_attr_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_def\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr_def.type.startswith(\u001b[33m\"\u001b[39m\u001b[33mlist(\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    331\u001b[39m   _SatisfiesLengthConstraint(\u001b[38;5;28mlen\u001b[39m(value), attr_def, key, op_type_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/framework/op_def_library.py:858\u001b[39m, in \u001b[36mvalue_to_attr_value\u001b[39m\u001b[34m(value, attr_type, arg_name)\u001b[39m\n\u001b[32m    856\u001b[39m   attr_value.shape.CopyFrom(_MakeShape(value, arg_name))\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m attr_type == \u001b[33m\"\u001b[39m\u001b[33mlist(shape)\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m858\u001b[39m   attr_value.list.shape.extend([\u001b[43m_MakeShape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[32m    859\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m attr_type == \u001b[33m\"\u001b[39m\u001b[33mtensor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    860\u001b[39m   attr_value.tensor.CopyFrom(_MakeTensor(value, arg_name))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/framework/op_def_library.py:213\u001b[39m, in \u001b[36m_MakeShape\u001b[39m\u001b[34m(v, arg_name)\u001b[39m\n\u001b[32m    211\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m v\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_shape\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    215\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError converting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (arg name = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) to a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    216\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/ITCS 3162/final-project/.venv/lib/python3.13/site-packages/tensorflow/python/framework/tensor_shape.py:1450\u001b[39m, in \u001b[36mTensorShape.as_proto\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1447\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m tensor_shape_pb2.TensorShapeProto(unknown_rank=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1449\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m tensor_shape_pb2.TensorShapeProto(dim=[\n\u001b[32m-> \u001b[39m\u001b[32m1450\u001b[39m       \u001b[43mtensor_shape_pb2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensorShapeProto\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m          \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dims\n\u001b[32m   1452\u001b[39m   ])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === RUN EXPERIMENTS ===\n",
    "\n",
    "# Refern to experiments_results.csv for saved results\n",
    "# As this is a VERY long running cell (30-60 minutes on a decent GPU)\n",
    "# Conisider only running with a subset of options for quick testing\n",
    "\n",
    "# Run all experiments (this will take a while with DL models)\n",
    "results_df = run_all_experiments(\n",
    "    full_df,\n",
    "    run_baselines=True,\n",
    "    run_ml=True,\n",
    "    run_dl=True,       # Set False for quick test\n",
    "    run_recursive=True  # Set False for quick test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VIEW RESULTS ===\n",
    "\n",
    "print(\"\\n📊 ALL RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "display(results_df.sort_values(['horizon', 'rmse']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BEST MODEL BY HORIZON ===\n",
    "\n",
    "print(\"\\n🏆 BEST MODEL BY HORIZON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for horizon in HORIZONS:\n",
    "    subset = results_df[results_df['horizon'] == horizon]\n",
    "    if len(subset) == 0:\n",
    "        continue\n",
    "    best = subset.loc[subset['rmse'].idxmin()]\n",
    "    print(f\"\\nHorizon {horizon}:\")\n",
    "    print(f\"  Best: {best['model']} ({best['strategy']}, seq={best['seq_length']})\")\n",
    "    print(f\"  RMSE: {best['rmse']:.4f} | MAE: {best['mae']:.4f} | R²: {best['r2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DIRECT VS RECURSIVE COMPARISON ===\n",
    "\n",
    "print(\"\\n⚔️  DIRECT vs RECURSIVE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for horizon in [3, 6, 12]:\n",
    "    direct = results_df[(results_df['horizon'] == horizon) & (results_df['strategy'] == 'direct')]\n",
    "    recursive = results_df[(results_df['horizon'] == horizon) & (results_df['strategy'] == 'recursive')]\n",
    "    \n",
    "    if len(direct) == 0 or len(recursive) == 0:\n",
    "        continue\n",
    "    \n",
    "    best_direct = direct.loc[direct['rmse'].idxmin()]\n",
    "    best_recursive = recursive.loc[recursive['rmse'].idxmin()]\n",
    "    \n",
    "    print(f\"\\nHorizon {horizon}:\")\n",
    "    print(f\"  Direct:    {best_direct['model']:<25} RMSE={best_direct['rmse']:.4f}\")\n",
    "    print(f\"  Recursive: {best_recursive['model']:<25} RMSE={best_recursive['rmse']:.4f}\")\n",
    "    \n",
    "    diff = (best_recursive['rmse'] - best_direct['rmse']) / best_direct['rmse'] * 100\n",
    "    winner = \"✅ Direct\" if diff > 0 else \"✅ Recursive\"\n",
    "    print(f\"  {winner} wins by {abs(diff):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ML VS DL COMPARISON ===\n",
    "\n",
    "print(\"\\n🤖 ML vs DEEP LEARNING COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ml_models = list(get_ml_models().keys())\n",
    "dl_models = list(get_dl_models().keys())\n",
    "\n",
    "for horizon in HORIZONS:\n",
    "    direct = results_df[(results_df['horizon'] == horizon) & (results_df['strategy'] == 'direct')]\n",
    "    \n",
    "    ml_results = direct[direct['model'].isin(ml_models)]\n",
    "    dl_results = direct[direct['model'].isin(dl_models)]\n",
    "    \n",
    "    if len(ml_results) == 0 or len(dl_results) == 0:\n",
    "        continue\n",
    "    \n",
    "    best_ml = ml_results.loc[ml_results['rmse'].idxmin()]\n",
    "    best_dl = dl_results.loc[dl_results['rmse'].idxmin()]\n",
    "    \n",
    "    print(f\"\\nHorizon {horizon}:\")\n",
    "    print(f\"  Best ML: {best_ml['model']:<15} RMSE={best_ml['rmse']:.4f}\")\n",
    "    print(f\"  Best DL: {best_dl['model']:<15} RMSE={best_dl['rmse']:.4f}\")\n",
    "    \n",
    "    winner = \"ML\" if best_ml['rmse'] < best_dl['rmse'] else \"DL\"\n",
    "    diff = abs(best_ml['rmse'] - best_dl['rmse']) / min(best_ml['rmse'], best_dl['rmse']) * 100\n",
    "    print(f\"  ✅ {winner} wins by {diff:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE ===\n",
    "\n",
    "results_df.to_csv('experiment_results.csv', index=False)\n",
    "print(\"✅ Results saved to experiment_results.csv\")\n",
    "\n",
    "# Also save a summary\n",
    "summary = results_df.groupby(['horizon', 'strategy']).apply(\n",
    "    lambda x: x.loc[x['rmse'].idxmin()][['model', 'seq_length', 'rmse', 'r2']]\n",
    ").reset_index()\n",
    "summary.to_csv('experiment_summary.csv', index=False)\n",
    "print(\"✅ Summary saved to experiment_summary.csv\")\n",
    "\n",
    "display(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
